{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11a4aea2-3193-4654-8078-f2e6fe5f5a7a",
   "metadata": {},
   "source": [
    "# 2 - Data Preprocessing (Part 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa733922-64a8-45d2-bdc6-25540561a38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# remove tweets\n",
    "import rt\n",
    "\n",
    "# import data\n",
    "df = pd.read_csv(\"inputs/tweets_raw.csv\")\n",
    "\n",
    "# drop columns\n",
    "df.drop(columns = [\"user_location\", \"coordinates\", \"place\"], inplace = True)\n",
    "\n",
    "# rename columns\n",
    "df.rename(columns = {\"rawContent\" : \"content\", \"id\" : \"tweet_id\"}, inplace = True)\n",
    "\n",
    "# convert datetime to date\n",
    "df[\"date\"] = df[\"date\"].apply(lambda x: x[:10])\n",
    "\n",
    "# convert uppercase letters to lowercase letters\n",
    "df[\"content\"] = df[\"content\"].str.lower()\n",
    "\n",
    "# convert integer to string\n",
    "df[\"tweet_id\"] = df[\"tweet_id\"].astype(str)\n",
    "\n",
    "# convert uppercase letters to lowercase letters\n",
    "df[\"user_username\"] = df[\"user_username\"].str.lower()\n",
    "\n",
    "# convert integer to string\n",
    "df[\"conversation_id\"] = df[\"conversation_id\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6def94c4-3448-412b-a075-8ad7ce2bc1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b49a9e-fe4b-42f3-8d52-189bdf075c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d031921-2dce-4de2-9758-9e9bcf1f2b93",
   "metadata": {},
   "source": [
    "## 1.1. Remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119618d1-94f5-49bd-9c4e-def96e6975b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = rt.remove_tweets(df = df,\n",
    "                      condition = ~df[[\"content\", \"user_username\"]].duplicated(),\n",
    "                      column = \"content\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e807a9f-fb18-43df-b1eb-3e3d32e2c95c",
   "metadata": {},
   "source": [
    "## Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbdd31a-989c-48c5-a1fe-9f163b1672ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "converge = [\"@converge_csu\", \"@experiencecnvrg\"]\n",
    "\n",
    "globe = [\"@enjoyglobe\", \"@talk2globe\"]\n",
    "\n",
    "pldt = [\"@pldthome\", \"@pldtenterprise\", \"@pldtent_cares\", \"@pldt_cares\", \"@pldt\"]\n",
    "\n",
    "tags = converge + globe + pldt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41bfdf0-ab89-4a00-a636-7f2d6ad318c5",
   "metadata": {},
   "source": [
    "## 1.2. Remove tweets from telecommunication companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d6b284-b316-4d1c-8635-0dc9c921b8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = rt.remove_tweets(df = df,\n",
    "                      condition = ~df[\"user_username\"].isin([tag.strip(\"@\") for tag in tags]),\n",
    "                      column = \"content\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b9a3bb-49df-49fd-87e5-7783e698193b",
   "metadata": {},
   "source": [
    "## 1.3. Remove tweets that tagged less or more than 1 company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9042d9-590e-405a-823d-175bcf25b7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def company(x):\n",
    "    for i in converge:\n",
    "        x = x.replace(i, \"@company_a\")\n",
    "    for i in globe:\n",
    "        x = x.replace(i, \"@company_b\")\n",
    "    for i in pldt:\n",
    "        x = x.replace(i, \"@company_c\")\n",
    "    return x\n",
    "\n",
    "df[\"content_1\"] = df[\"content\"].apply(lambda x: company(x))\n",
    "\n",
    "df[\"company_a\"] = df[\"content_1\"].apply(lambda x: 1 if \"@company_a\" in x else 0)\n",
    "df[\"company_b\"] = df[\"content_1\"].apply(lambda x: 1 if \"@company_b\" in x else 0)\n",
    "df[\"company_c\"] = df[\"content_1\"].apply(lambda x: 1 if \"@company_c\" in x else 0)\n",
    "\n",
    "df[\"company\"] = df[\"company_a\"] + df[\"company_b\"] + df[\"company_c\"]\n",
    "\n",
    "df = rt.remove_tweets(df = df,\n",
    "                      condition = df[\"company\"] == 1,\n",
    "                      column = \"content_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46058e7f-94fc-41cf-b7c0-268c8fceef76",
   "metadata": {},
   "source": [
    "## X.1. Case folding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc10753-6c0d-4af6-a3a9-96bb9ee62dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"content_1\"] = df[\"content_1\"].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532df67a-9245-427e-a15d-7c95ab3f9dc1",
   "metadata": {},
   "source": [
    "## X.2. Remove hastags, mentions, links, and non-alphabetical characters (including numerical characters and special characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eeff65e-1dc2-4257-97e8-70e70def83ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "\n",
    "def remove(x):\n",
    "    \n",
    "    # remove non-white space characters after # (hashtags)\n",
    "    # remove non-white space characters after @ (mentions)\n",
    "    # remove non-white space characters after http (links)\n",
    "    x = re.sub(\"(\\#\\S+)|(\\@\\S+)|(http\\S+)\", \"\", x)\n",
    "    \n",
    "    # substitute non-alphabetical characters into a single space\n",
    "    x = re.sub(\"([^a-z])\", \" \", x)\n",
    "    \n",
    "    # substitute multiple spaces into a single space\n",
    "    x = re.sub(\"(\\s+)\", \" \", x)\n",
    "    \n",
    "    x = x.strip()\n",
    "    \n",
    "    return x\n",
    "\n",
    "df[\"content_2\"] = df[\"content_1\"].apply(lambda x: remove(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22856704-e2ea-41a5-aa16-06b45644d6bc",
   "metadata": {},
   "source": [
    "## X.3. Remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8100983f-ef85-4270-9911-9bb083f70ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# english stop words\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "sw_english = stopwords.words(\"english\")\n",
    "\n",
    "# tagalog stop words\n",
    "\n",
    "import advertools\n",
    "\n",
    "sw_tagalog = list(advertools.stopwords[\"tagalog\"])\n",
    "\n",
    "# domain stop words\n",
    "\n",
    "sw_domain = [\"converge\", \"globe\", \"pldt\"]\n",
    "\n",
    "# stop words\n",
    "\n",
    "sw = sw_english + sw_tagalog + sw_domain\n",
    "\n",
    "sw = [remove(i) for i in sw]\n",
    "\n",
    "# remove stop words\n",
    "\n",
    "df[\"content_3\"] = df[\"content_2\"].apply(lambda x: \" \".join([i for i in x.split() if i not in sw]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf70c595-6fbc-472a-bd7d-d7a328de41c5",
   "metadata": {},
   "source": [
    "## X.4. Remove low quality words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6146a75-21ac-4079-bce4-e3476b3086b8",
   "metadata": {},
   "source": [
    "* Remove words with a character count less than or equal to 2 and greater than or equal to 30.\n",
    "* Remove words that are permutations of one or two alphabetical characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958e6985-6240-4135-8933-84622a53b130",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_low_quality_words(x):\n",
    "    \n",
    "    lst = list()\n",
    "    \n",
    "    for i in x.split():\n",
    "        if len(i) > 2:\n",
    "            if len(i) < 30:\n",
    "                if len(set(i)) > 2:\n",
    "                    lst.append(i)\n",
    "                    \n",
    "    return \" \".join(lst)\n",
    "\n",
    "df[\"content_4\"] = df[\"content_3\"].apply(lambda x: remove_low_quality_words(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865e84af-7f9e-4499-83dc-60f3a311ac74",
   "metadata": {
    "tags": []
   },
   "source": [
    "## X.5. Filter by word count 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1846542e-ac69-4f37-a25a-c904764e39f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"word_count_1\"] = df[\"content_4\"].apply(lambda x: len(x.split()))\n",
    "\n",
    "df = rt.remove_tweets(df = df,\n",
    "                      condition = df[\"word_count_1\"] > 2,\n",
    "                      column = \"content_4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db451a47-3053-419a-b5f6-385c140a16a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt.rt(345667, 260313)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b9fd82-4fe9-4e81-9cd7-fdcbb2ccb16c",
   "metadata": {},
   "source": [
    "## Export data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a800bec-c665-4ee0-8ea8-485d458e4706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"inputs/tweets_1.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76fbb9a-5ed2-488d-a9ea-c8f1017db3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51bcacc-dd57-43a4-8363-362b89db3aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
